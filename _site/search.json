[
  {
    "objectID": "content/01_journal/01_machine_learning_fundamentals.html",
    "href": "content/01_journal/01_machine_learning_fundamentals.html",
    "title": "Machine Learning Fundamentals",
    "section": "",
    "text": "Loading Libraries\n\nlibrary(tidyverse)\nlibrary(tidyquant)\nlibrary(broom)\nlibrary(umap)\nlibrary(lubridate)\nlibrary(plotly)\n\nLoading Data\n\nsp_500_index_tbl <- read_rds(\"../../../sp_500_index_tbl.rds\")\nsp_500_prices_tbl <- read_rds(\"../../../sp_500_prices_tbl.rds\")\n\nsp_500_index_tbl %>% glimpse()\n\n#> Rows: 506\n#> Columns: 5\n#> $ symbol      <chr> \"MSFT\", \"AAPL\", \"AMZN\", \"BRK.B\", \"FB\", \"JNJ\", \"JPM\", \"GOOG…\n#> $ company     <chr> \"Microsoft Corporation\", \"Apple Inc.\", \"Amazon.com Inc.\", …\n#> $ weight      <dbl> 0.035896594, 0.032998436, 0.028348455, 0.017144931, 0.0167…\n#> $ sector      <chr> \"Information Technology\", \"Information Technology\", \"Consu…\n#> $ shares_held <dbl> 84853600, 49533308, 4510051, 21364490, 26385216, 29452358,…\n\nsp_500_prices_tbl %>% glimpse()\n\n#> Rows: 1,225,765\n#> Columns: 8\n#> $ symbol   <chr> \"MSFT\", \"MSFT\", \"MSFT\", \"MSFT\", \"MSFT\", \"MSFT\", \"MSFT\", \"MSFT…\n#> $ date     <date> 2009-01-02, 2009-01-05, 2009-01-06, 2009-01-07, 2009-01-08, …\n#> $ open     <dbl> 19.53, 20.20, 20.75, 20.19, 19.63, 20.17, 19.71, 19.52, 19.53…\n#> $ high     <dbl> 20.40, 20.67, 21.00, 20.29, 20.19, 20.30, 19.79, 19.99, 19.68…\n#> $ low      <dbl> 19.37, 20.06, 20.61, 19.48, 19.55, 19.41, 19.30, 19.52, 19.01…\n#> $ close    <dbl> 20.33, 20.52, 20.76, 19.51, 20.12, 19.52, 19.47, 19.82, 19.09…\n#> $ volume   <dbl> 50084000, 61475200, 58083400, 72709900, 70255400, 49815300, 5…\n#> $ adjusted <dbl> 15.86624, 16.01451, 16.20183, 15.22628, 15.70234, 15.23408, 1…\n\n\nStep 1\n\nsp_500_daily_returns_tbl <- sp_500_prices_tbl %>% \n  select(symbol, date, adjusted) %>% \n  filter(year(date) >= 2018) %>% \n  group_by(symbol) %>% \n  mutate(prev_adjusted = lag(adjusted)) %>% \n  drop_na() %>% \n  mutate(diff = adjusted - prev_adjusted) %>% \n  mutate(pct_return = diff / prev_adjusted) %>% \n  ungroup() %>% \n  select(symbol, date, pct_return)\n\nsp_500_daily_returns_tbl\n\n\n\n  \n\n\n\nStep 2\n\nstock_date_matrix_tbl <- sp_500_daily_returns_tbl %>% \n  pivot_wider(names_from = date, values_from = pct_return) %>% \n  replace(is.na(.), 0)\n\nStep 3\n\nkmeans_obj <- stock_date_matrix_tbl %>% \n  select(-symbol) %>% \n  kmeans(centers=4, nstart=20)\n\nkmeans_obj %>% glance()\n\n\n\n  \n\n\n\nStep 4\n\nkmeans_mapper <- function(center = 3) {\n    stock_date_matrix_tbl %>%\n        select(-symbol) %>%\n        kmeans(centers = center, nstart = 20)\n}\n\nk_means_mapped_tbl <- tibble(centers = 1:30) %>% \n  mutate(k_means = map(centers, kmeans_mapper)) %>% \n  mutate(glance = map(k_means, glance))\n\nk_means_mapped_tbl\n\n\n\n  \n\n\nk_means_mapped_tbl %>% \n  unnest(glance) %>%\n  \n  ggplot(aes(x = centers, y = tot.withinss)) +\n  \n  geom_point() +\n  geom_line() +\n\n  labs(\n    title = \"Scree Plot\"\n  ) +\n  \n  theme_gray()\n\n\n\n\n\n\n\nStep 5\n\numap_results <- stock_date_matrix_tbl %>% \n  select(-symbol) %>% \n  umap()\n\numap_results_tbl <- umap_results$layout %>% \n  as_tibble() %>% \n  bind_cols(stock_date_matrix_tbl %>% select(symbol), .)\n\numap_results_tbl %>% \n  ggplot(aes(x=V1, y=V2)) +\n  \n  geom_point(alpha=0.5) +\n  \n  labs(title = \"UMAP Projection\") +\n  \n  theme_tq()\n\n\n\n\n\n\n\nStep 6\n\nk_means_10_obj <- k_means_mapped_tbl %>% \n  pull(k_means) %>% \n  pluck(10)\n\numap_kmeans_results_tbl <- k_means_10_obj %>% \n  augment(stock_date_matrix_tbl) %>% \n  select(symbol, .cluster) %>% \n  left_join(umap_results_tbl, join_by(symbol == symbol)) %>% \n  left_join(sp_500_index_tbl %>% select(symbol, company, sector), join_by(symbol == symbol))\n\n\ng <- umap_kmeans_results_tbl %>% \n  ggplot(aes(x = V1, y = V2, color = .cluster, text = company)) +\n  \n  geom_point(alpha = 0.5) +\n  \n  scale_color_manual(values = c(\"#3388FF\", \"#8833FF\", \"#33FF88\", \"#FF3333\", \"#FF3388\",\n                                \"#FF8833\", \"#FFFF33\", \"#FF33FF\", \"#33FFFF\", \"#333333\")) +\n  \n  theme_gray() +\n  theme(legend.position=\"none\")\n\n\ng %>%\n  ggplotly(tooltip = \"text\")"
  },
  {
    "objectID": "content/01_journal/02_supervised_ml_regression.html",
    "href": "content/01_journal/02_supervised_ml_regression.html",
    "title": "Supervised ML-Regression",
    "section": "",
    "text": "Importing Libraries\n\nlibrary(tidyverse)\nlibrary(parsnip)\nlibrary(rsample)\nlibrary(recipes)\nlibrary(workflows)\nlibrary(yardstick)\n\nDefining Model\n\nlr_mod <- linear_reg(mode = \"regression\") %>% \n  set_engine(\"lm\")\n\nLoading Data\n\nbike_features_tbl <- readRDS(\"../../../bike_features_tbl.rds\")\nglimpse(bike_features_tbl)\n\n#> Rows: 231\n#> Columns: 67\n#> $ bike_id                     <dbl> 2875, 2873, 2874, 2876, 2877, 2225, 2091, …\n#> $ model                       <chr> \"Aeroad CF SL Disc 8.0 Di2\", \"Aeroad CF SL…\n#> $ model_year                  <dbl> 2020, 2020, 2020, 2020, 2020, 2019, 2019, …\n#> $ frame_material              <chr> \"carbon\", \"carbon\", \"carbon\", \"carbon\", \"c…\n#> $ weight                      <dbl> 7.60, 7.27, 7.10, 7.73, 7.83, 6.80, 6.80, …\n#> $ price                       <dbl> 4579, 6919, 6429, 5069, 3609, 6139, 5359, …\n#> $ category_1                  <chr> \"Road\", \"Road\", \"Road\", \"Road\", \"Road\", \"R…\n#> $ category_2                  <chr> \"Race\", \"Race\", \"Race\", \"Race\", \"Race\", \"R…\n#> $ category_3                  <chr> \"Aeroad\", \"Aeroad\", \"Aeroad\", \"Aeroad\", \"A…\n#> $ gender                      <chr> \"unisex\", \"unisex\", \"unisex\", \"unisex\", \"u…\n#> $ url                         <chr> \"https://www.canyon.com/en-de/road-bikes/r…\n#> $ Frame                       <chr> \"Canyon Aeroad CF SL Disc\", \"Canyon Aeroad…\n#> $ Fork                        <chr> \"Canyon FK0041 CF SLX Disc\", \"Canyon FK004…\n#> $ `Rear Derailleur`           <chr> \"Shimano Ultegra Di2 R8050 SS\", \"SRAM RED …\n#> $ `Front Derailleur`          <chr> \"Shimano Ultegra Di2 R8050\", \"SRAM RED eTa…\n#> $ Cassette                    <chr> \"Shimano Ultegra R8000, 11-speed, 11-28T\",…\n#> $ Crank                       <chr> \"Shimano Ultegra R8000\", \"SRAM RED D1\", \"S…\n#> $ `Bottom bracket`            <chr> \"Shimano Pressfit BB72\", \"SRAM Pressfit RE…\n#> $ `Thru Axle`                 <chr> \"Canyon Thru Axle\", \"Canyon Thru Axle\", \"C…\n#> $ Cockpit                     <chr> \"Canyon H36 Aerocockpit CF\", \"Canyon H36 A…\n#> $ Saddle                      <chr> \"Selle Italia SLR\", \"Selle Italia SLR\", \"S…\n#> $ Seatpost                    <chr> \"Canyon S27 Aero VCLS CF\", \"Canyon S27 Aer…\n#> $ Pedals                      <chr> \"None included\", \"None included\", \"None in…\n#> $ `Derailleur hanger`         <chr> \"Shop Derailleur Hanger GP0211-01\", \"Shop …\n#> $ Battery                     <chr> \"\", \"SRAM eTap Powerpack\", \"\", \"SRAM eTap …\n#> $ Brake                       <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Shift Lever`               <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"Shimano Di2 Remot…\n#> $ Chain                       <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"Shimano CN-HG901 …\n#> $ Stem                        <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"Canyon V13\", …\n#> $ Handlebar                   <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"Canyon H16 Ae…\n#> $ Headset                     <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ Motor                       <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Battery Charger`           <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Flat Pedals`               <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ Chainguard                  <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Aero Bar`                  <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Brake Lever / Master`      <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Wheel Tire System`         <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Suspension Fork`           <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Disc Brake`                <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ Grips                       <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ Chainring                   <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ Display                     <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ Modeswitch                  <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Rear Shock`                <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ Light                       <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ Fender                      <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Bike Racks`                <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Brake 1`                   <chr> \"\", \"\", \"\", \"\", \"\", \"SRAM S-900 Direct Mou…\n#> $ `Brake 2`                   <chr> \"\", \"\", \"\", \"\", \"\", \"SRAM S-900 Direct Mou…\n#> $ `Shift-/ Brake Lever 1`     <chr> \"Shimano Ultegra Di2 R8070, 11-speed\", \"SR…\n#> $ `Shift-/ Brake Lever 2`     <chr> \"Shimano Ultegra Di2 R8070, 11-speed\", \"SR…\n#> $ `Wheel 1`                   <chr> \"DT Swiss ARC 1400 Dicut\", \"DT Swiss ARC 1…\n#> $ `Wheel 2`                   <chr> \"DT Swiss ARC 1400 Dicut\", \"DT Swiss ARC 1…\n#> $ `Tyre 1`                    <chr> \"Continental Grand Prix 5000 / Attack  23 …\n#> $ `Tyre 2`                    <chr> \"Continental Grand Prix 5000, 25 mm\", \"Con…\n#> $ `Handlebar Tape 1`          <chr> \"Canyon Ergospeed Gel\", \"Canyon Ergospeed …\n#> $ `Handlebar Tape 2`          <chr> \"Canyon bar-end plug\", \"Canyon bar-end plu…\n#> $ `Manuals and Accessories 1` <chr> \"Canyon tool case\", \"Canyon tool case\", \"C…\n#> $ `Manuals and Accessories 2` <chr> \"DT Swiss warranty & intended use manual\",…\n#> $ `Manuals and Accessories 3` <chr> \"Canyon starter box\", \"Canyon starter box\"…\n#> $ `Manuals and Accessories 4` <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"BAG R…\n#> $ `Manuals and Accessories 5` <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Manuals and Accessories 6` <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Manuals and Accessories 7` <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Manuals and Accessories 8` <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Brake Rotor`               <list> \"Shimano RT800\", \"SRAM Centerline X\", \"Sh…\n\n\nSplitting Data\n\nset.seed(184375)\n\nsplit_obj  <- initial_split(bike_features_tbl, prop = 0.8)\n\ntrain_tbl <- training(split_obj)\ntest_tbl <- testing(split_obj)\n\ntrain_tbl <- train_tbl %>% set_names(str_replace_all(names(train_tbl), \" |-\", \"_\"))\ntest_tbl  <- test_tbl  %>% set_names(str_replace_all(names(test_tbl),  \" |-\", \"_\"))\n\nCreating Recipe\n\nbikes_rec <- \n  recipe(price ~ category_2 + frame_material + weight, data = train_tbl) %>% \n  step_dummy(all_nominal())\n\nCombining to Workflow\n\nbikes_wflow <- \n  workflow() %>% \n  add_model(lr_mod) %>% \n  add_recipe(bikes_rec)\n\nFitting\n\nbikes_fit <- bikes_wflow %>% \n  fit(data = train_tbl)\n\nEvaluation\n\ncalc_metrics <- function(model, new_data = test_tbl) {\n\n    model %>%\n        predict(new_data = new_data) %>%\n\n        bind_cols(new_data %>% select(price)) %>%\n        yardstick::metrics(truth = price, estimate = .pred)\n}\n\ncalc_metrics(bikes_fit, new_data = test_tbl)"
  },
  {
    "objectID": "content/01_journal/03_automated_machine_learning_1.html",
    "href": "content/01_journal/03_automated_machine_learning_1.html",
    "title": "Automated Machine Learning with H20 (I)",
    "section": "",
    "text": "Importing Libraries\n\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(skimr)\nlibrary(GGally)\n\nLoading Data\n\nemployee_attrition_tbl <- read.csv(\"../../../employee_attrition.csv\")\n\npath_data_definitions <- \"../../../data_definitions.xlsx\"\ndefinitions_raw_tbl   <- read_excel(path_data_definitions, sheet = 1, col_names = FALSE)\n\nDefinition of data-wrangling functions\n\nShow the code# Function to calculate attrition cost\ncalculate_attrition_cost <- function(\n\n  # Employee\n  n                    = 1,\n  salary               = 80000,\n\n  # Direct Costs\n  separation_cost      = 500,\n  vacancy_cost         = 10000,\n  acquisition_cost     = 4900,\n  placement_cost       = 3500,\n\n  # Productivity Costs\n  net_revenue_per_employee = 250000,\n  workdays_per_year        = 240,\n  workdays_position_open   = 40,\n  workdays_onboarding      = 60,\n  onboarding_efficiency    = 0.50\n\n) {\n\n  # Direct Costs\n  direct_cost <- sum(separation_cost, vacancy_cost, acquisition_cost, placement_cost)\n\n  # Lost Productivity Costs\n  productivity_cost <- net_revenue_per_employee / workdays_per_year *\n    (workdays_position_open + workdays_onboarding * onboarding_efficiency)\n\n  # Savings of Salary & Benefits (Cost Reduction)\n  salary_benefit_reduction <- salary / workdays_per_year * workdays_position_open\n\n  # Estimated Turnover Per Employee\n  cost_per_employee <- direct_cost + productivity_cost - salary_benefit_reduction\n\n  # Total Cost of Employee Turnover\n  total_cost <- n * cost_per_employee\n\n  return(total_cost)\n\n}\n\n\ncount_to_pct <- function(data, ..., col = n) {\n\n  # capture the dots\n  grouping_vars_expr <- quos(...)\n  col_expr <- enquo(col)\n\n  ret <- data %>%\n    group_by(!!! grouping_vars_expr) %>%\n    mutate(pct = (!! col_expr) / sum(!! col_expr)) %>%\n    ungroup()\n\n  return(ret)\n\n}\n\n\nassess_attrition <- function(data, attrition_col, attrition_value, baseline_pct) {\n\n  attrition_col_expr <- enquo(attrition_col)\n\n  data %>%\n  \n    # Use parenthesis () to give tidy eval evaluation priority\n    filter((!! attrition_col_expr) %in% attrition_value) %>%\n    arrange(desc(pct)) %>%\n    mutate(\n      # Function inputs in numeric format (e.g. baseline_pct = 0.088 don't require tidy eval)\n      above_industry_avg = case_when(\n        pct > baseline_pct ~ \"Yes\",\n        TRUE ~ \"No\"\n      )\n    )\n}\n\n\nData-Wrangling\n\ndept_job_role_tbl <- employee_attrition_tbl %>%\n  select(EmployeeNumber, Department, JobRole, PerformanceRating, Attrition)\n\n\ndept_job_role_tbl %>%\n  count(Department, JobRole, Attrition) %>%\n  count_to_pct(Department, JobRole) %>%\n  assess_attrition(Attrition, attrition_value = \"Yes\", baseline_pct = 0.088) %>%\n  mutate(\n    cost_of_attrition = calculate_attrition_cost(n = n, salary = 80000)\n  )\n\n\n\n  \n\n\n\nDefinition of plot_ggpairs\n\nShow the codeplot_ggpairs <- function(data, color = NULL, density_alpha = 0.5) {\n    \n    color_expr <- enquo(color)\n    \n    if (rlang::quo_is_null(color_expr)) {\n        \n        g <- data %>%\n            ggpairs(lower = \"blank\") \n        \n    } else {\n        \n        color_name <- quo_name(color_expr)\n        \n        g <- data %>%\n            ggpairs(mapping = aes_string(color = color_name), \n                    lower = \"blank\", \n                    legend = 1,\n                    diag = list(continuous = wrap(\"densityDiag\", \n                                                  alpha = density_alpha))) +\n            theme(legend.position = \"bottom\")\n    }\n    \n    return(g)\n    \n}\n\n\nExplore Features by Category\n\n#   1. Descriptive features: age, gender, marital status \nemployee_attrition_tbl %>%\n    select(Attrition, Age, Gender, MaritalStatus, NumCompaniesWorked, Over18, DistanceFromHome) %>%\n    plot_ggpairs(Attrition)\n\n\n\n\n\n\n\n\n#   2. Employment features: department, job role, job level\nemployee_attrition_tbl %>%\n    select(Attrition, contains(\"employee\"), contains(\"department\"), contains(\"job\")) %>%\n    plot_ggpairs(Attrition) \n\n\n\n\n\n\n\n\n#   3. Compensation features: HourlyRate, MonthlyIncome, StockOptionLevel \nemployee_attrition_tbl %>%\n    select(Attrition, contains(\"income\"), contains(\"rate\"), contains(\"salary\"), contains(\"stock\")) %>%\n    plot_ggpairs(Attrition)\n\n\n\n\n\n\n\n\n#   4. Survey Results: Satisfaction level, WorkLifeBalance \nemployee_attrition_tbl %>%\n    select(Attrition, contains(\"satisfaction\"), contains(\"life\")) %>%\n    plot_ggpairs(Attrition)\n\n\n\n\n\n\n\n\n#   5. Performance Data: Job Involvment, Performance Rating\nemployee_attrition_tbl %>%\n    select(Attrition, contains(\"performance\"), contains(\"involvement\")) %>%\n    plot_ggpairs(Attrition)\n\n\n\n\n\n\n\n\n#   6. Work-Life Features \nemployee_attrition_tbl %>%\n    select(Attrition, contains(\"overtime\"), contains(\"travel\")) %>%\n    plot_ggpairs(Attrition)\n\n\n\n\n\n\n\n\n#   7. Training and Education \nemployee_attrition_tbl %>%\n    select(Attrition, contains(\"training\"), contains(\"education\")) %>%\n    plot_ggpairs(Attrition)\n\n\n\n\n\n\n\n\n#   8. Time-Based Features: Years at company, years in current role\nemployee_attrition_tbl %>%\n    select(Attrition, contains(\"years\")) %>%\n    plot_ggpairs(Attrition)\n\n\n\n\n\n\n\nFeature Investigation\n1. Compensation Features\nWhat can you deduce about the interaction between Monthly Income and Attrition?\n\nThose that are leaving have a lower Monthly Income\n\n2. Compensation Features\nWhat can you deduce about the interaction between Percent Salary Hike and Attrition?\n\nThose that are leaving have lower Percent Salary Hike\n\n3. Compensation Features\nWhat can you deduce about the interaction between Stock Option Level and Attrition?\n\nIt’s difficult to deduce anything based on the visualization\n\n4. Survey Results\nWhat can you deduce about the interaction between Environment Satisfaction and Attrition?\n\nA higher proportion of those leaving have a low environment satisfaction level\n\n5. Survey Results\nWhat can you deduce about the interaction between Work Life Balance and Attrition\n\nThose that are staying have a higher density of 2’s and 3’s\n\n6. Performance Data\nWhat Can you deduce about the interaction between Job Involvement and Attrition?\n\nThose that are leaving have a lower density of 3’s and 4’s\n\n7. Work-Life Features\nWhat can you deduce about the interaction between Over Time and Attrition?\n\nThe proportion of those leaving that are working Over Time are high compared to those that are not leaving\n\n8. Training and Education\nWhat can you deduce about the interaction between Training Times Last Year and Attrition\n\nIt’s difficult to deduce anything based on the visualization\n\n9. Time-Based Features\nWhat can you deduce about the interaction between Years At Company and Attrition\n\nPeople that leave tend to have less working years at the company\n\n10. Time-Based Features\nWhat can you deduce about the interaction between Years Since Last Promotion and Attrition?\n\nThose that are leaving have fewer years since last promotion than those that are staying"
  },
  {
    "objectID": "content/01_journal/04_automated_machine_learning_2.html",
    "href": "content/01_journal/04_automated_machine_learning_2.html",
    "title": "Automated Machine Learning with H20 (II)",
    "section": "",
    "text": "Importing Libraries\n\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(rsample)\nlibrary(recipes)\nlibrary(h2o)\n\nInitializing H2O\n\nh2o.init()\nset.seed(seed = 1113)\n\nLoading and Splitting Data\n\nproduct_backorder_tbl <- read.csv(\"../../../product_backorders.csv\")\n\nsplit_obj <- rsample::initial_split(product_backorder_tbl, prop = 0.85)\n\ntrain_readable_tbl <- training(split_obj)\ntest_readable_tbl <- testing(split_obj)\n\nRecipe Definition and Application\n\nrecipe_obj <- recipe(went_on_backorder ~ ., data = train_readable_tbl) %>% \n  update_role(sku, new_role = \"ID\") %>% \n  step_zv(all_predictors()) %>% \n  step_mutate_at(all_nominal(), fn = as.factor) %>% \n  prep()\n\ntrain_tbl <- bake(recipe_obj, new_data = train_readable_tbl)\ntest_tbl <- bake(recipe_obj, new_data = test_readable_tbl)\n\nsplit_h2o <- h2o.splitFrame(as.h2o(train_tbl), ratios = c(0.85), seed = 1234)\ntrain_h2o <- split_h2o[[1]]\nvalid_h2o <- split_h2o[[2]]\ntest_h2o <- as.h2o(test_tbl)\n\nAuto-Modeling\n\ny <- \"went_on_backorder\"\nx <- setdiff(names(train_h2o), c(y, \"sku\"))\n\nautoml_models_h2o <- h2o.automl(\n  x = x,\n  y = y,\n  training_frame = train_h2o,\n  validation_frame = valid_h2o,\n  leaderboard_frame = test_h2o,\n  max_runtime_secs = 30,\n  nfolds = 5\n)\n\n\nautoml_models_h2o@leaderboard\n\n#>                                                  model_id       auc   logloss\n#> 1                          GBM_4_AutoML_8_20230613_212052 0.9465800 0.1834729\n#> 2 StackedEnsemble_BestOfFamily_3_AutoML_8_20230613_212052 0.9459006 0.1797696\n#> 3 StackedEnsemble_BestOfFamily_2_AutoML_8_20230613_212052 0.9454242 0.1804093\n#> 4    StackedEnsemble_AllModels_1_AutoML_8_20230613_212052 0.9449883 0.1796356\n#> 5                          GBM_3_AutoML_8_20230613_212052 0.9433799 0.1852992\n#> 6                          GBM_2_AutoML_8_20230613_212052 0.9416835 0.1878870\n#>       aucpr mean_per_class_error      rmse        mse\n#> 1 0.7235563            0.1781963 0.2343908 0.05493906\n#> 2 0.7368489            0.1242785 0.2325751 0.05409118\n#> 3 0.7348444            0.1449337 0.2328003 0.05419600\n#> 4 0.7432835            0.1615650 0.2322328 0.05393208\n#> 5 0.7380727            0.1681595 0.2338296 0.05467627\n#> 6 0.7241084            0.1775996 0.2347489 0.05510705\n#> \n#> [13 rows x 7 columns]\n\n\nPrediction\n\nleader <- automl_models_h2o %>% h2o.get_best_model()\n\npredictions <- h2o.predict(leader, newdata = test_h2o)\n\n\npredictions\n\n#>   predict        No       Yes\n#> 1      No 0.7329215 0.2670785\n#> 2     Yes 0.3753872 0.6246128\n#> 3     Yes 0.5454352 0.4545648\n#> 4     Yes 0.6560820 0.3439180\n#> 5     Yes 0.1106067 0.8893933\n#> 6      No 0.8265082 0.1734918\n#> \n#> [2858 rows x 3 columns]\n\n\nSaving\n\nleader %>% h2o.saveModel(\"../../my_models/AutoML2_Model\")"
  },
  {
    "objectID": "content/01_journal/05_performance_measures.html",
    "href": "content/01_journal/05_performance_measures.html",
    "title": "Performance Measures",
    "section": "",
    "text": "Repeat of last Challenge\n\nShow the codelibrary(tidyverse)\nlibrary(readxl)\nlibrary(rsample)\nlibrary(recipes)\nlibrary(h2o)\nlibrary(cowplot)\nlibrary(glue)\n\nh2o.init()\nset.seed(seed = 1113)\n\ntheme_new <- theme(\n  legend.position  = \"bottom\",\n  legend.key       = element_blank(),,\n  panel.background = element_rect(fill   = \"transparent\"),\n  panel.border     = element_rect(color = \"black\", fill = NA, size = 0.5),\n  panel.grid.major = element_line(color = \"grey\", size = 0.333)\n)\n\nproduct_backorder_tbl <- read.csv(\"../../../product_backorders.csv\")\n\nsplit_obj <- rsample::initial_split(product_backorder_tbl, prop = 0.85)\n\ntrain_readable_tbl <- training(split_obj)\ntest_readable_tbl <- testing(split_obj)\n\nrecipe_obj <- recipe(went_on_backorder ~ ., data = train_readable_tbl) %>% \n  update_role(sku, new_role = \"ID\") %>% \n  step_zv(all_predictors()) %>% \n  step_mutate_at(all_nominal(), fn = as.factor) %>% \n  prep()\n\ntrain_tbl <- bake(recipe_obj, new_data = train_readable_tbl)\ntest_tbl <- bake(recipe_obj, new_data = test_readable_tbl)\n\nsplit_h2o <- h2o.splitFrame(as.h2o(train_tbl), ratios = c(0.85), seed = 1234)\ntrain_h2o <- split_h2o[[1]]\nvalid_h2o <- split_h2o[[2]]\ntest_h2o <- as.h2o(test_tbl)\n\ny <- \"went_on_backorder\"\nx <- setdiff(names(train_h2o), c(y, \"sku\"))\n\nautoml_models_h2o <- h2o.automl(\n  x = x,\n  y = y,\n  training_frame = train_h2o,\n  validation_frame = valid_h2o,\n  leaderboard_frame = test_h2o,\n  max_runtime_secs = 30,\n  nfolds = 5\n)\n\n\n1. Leaderboard Visualization\n\nplot_h2o_leaderboard <- function(h2o_leaderboard, order_by = c(\"auc\", \"logloss\"), \n                                 n_max = 20, size = 4, include_lbl = TRUE) {\n  \n  # Setup inputs\n  # adjust input so that all formats are working\n  order_by <- tolower(order_by[[1]])\n  \n  leaderboard_tbl <- h2o_leaderboard %>%\n    as_tibble() %>%\n    select(-c(aucpr, mean_per_class_error, rmse, mse)) %>% \n    mutate(model_type = str_extract(model_id, \"[^_]+\")) %>%\n    rownames_to_column(var = \"rowname\") %>%\n    mutate(model_id = paste0(rowname, \". \", model_id) %>% as.factor())\n  \n  # Transformation\n  if (order_by == \"auc\") {\n    \n    data_transformed_tbl <- leaderboard_tbl %>%\n      slice(1:n_max) %>%\n      mutate(\n        model_id   = as_factor(model_id) %>% reorder(auc),\n        model_type = as.factor(model_type)\n      ) %>%\n      pivot_longer(cols = -c(model_id, model_type, rowname), \n                   names_to = \"key\", \n                   values_to = \"value\", \n                   names_transform = list(key = forcats::fct_inorder)\n      )\n    \n  } else if (order_by == \"logloss\") {\n    \n    data_transformed_tbl <- leaderboard_tbl %>%\n      slice(1:n_max) %>%\n      mutate(\n        model_id   = as_factor(model_id) %>% reorder(logloss) %>% fct_rev(),\n        model_type = as.factor(model_type)\n      ) %>%\n      pivot_longer(cols = -c(model_id, model_type, rowname), \n                   names_to = \"key\", \n                   values_to = \"value\", \n                   names_transform = list(key = forcats::fct_inorder)\n      )\n    \n  } else {\n    # If nothing is supplied\n    stop(paste0(\"order_by = '\", order_by, \"' is not a permitted option.\"))\n  }\n  \n  # Visualization\n  g <- data_transformed_tbl %>%\n    ggplot(aes(value, model_id, color = model_type)) +\n    geom_point(size = size) +\n    facet_wrap(~ key, scales = \"free_x\") +\n    labs(title = \"Leaderboard Metrics\",\n         subtitle = paste0(\"Ordered by: \", toupper(order_by)),\n         y = \"Model Postion, Model ID\", x = \"\")\n  \n  if (include_lbl) g <- g + geom_label(aes(label = round(value, 2), \n                                           hjust = \"inward\"))\n  \n  return(g)\n  \n}\n\nautoml_models_h2o@leaderboard %>% plot_h2o_leaderboard()\n\n\n\n\n\n\n\n2. Tune a Model with Grid Search\n\ndeeplearning_h2o <- h2o.loadModel(\"../../my_models/PerfMeasures_Models/DeepLearning_1_AutoML_4_20230610_121831\")\n\nh2o.performance(deeplearning_h2o, newdata = test_h2o)\n\ndeeplearning_grid_01 <- h2o.grid(\n  \n  # See help page for available algos\n  algorithm = \"deeplearning\",\n  \n  # I just use the same as the object\n  grid_id = \"deeplearning_grid_01\",\n  \n  # The following is for ?h2o.deeplearning()\n  # predictor and response variables\n  x = x,\n  y = y,\n  \n  # training and validation frame and crossfold validation\n  training_frame   = train_h2o,\n  validation_frame = valid_h2o,\n  nfolds = 5,\n  \n  # Hyperparamters: Use deeplearning_h2o@allparameters to see all\n  hyper_params = list(\n    # Use some combinations (the first one was the original)\n    hidden = list(c(10, 10, 10), c(50, 20, 10), c(20, 20, 20)),\n    epochs = c(10, 50, 100)\n  )\n)\n\n\ndeeplearning_grid_01@summary_table\n\n\n\n  \n\n\n\n3. Visualize the trade of between the precision and the recall and the optimal threshold\n\ngbm_h2o <- h2o.loadModel(\"../../my_models/PerfMeasures_Models/GBM_4_AutoML_4_20230610_121831\")\n\ngbm_perf_h2o <- h2o.performance(gbm_h2o, newdata = test_h2o)\n\ngbm_perf_tbl <- gbm_perf_h2o %>% \n  h2o.metric() %>% \n  as_tibble()\n\ngbm_perf_tbl %>%\n  ggplot(aes(x = threshold)) +\n  geom_line(aes(y = precision), color = \"blue\", size = 1) +\n  geom_line(aes(y = recall), color = \"red\", size = 1) +\n  \n  # Insert line where precision and recall are harmonically optimized\n  geom_vline(xintercept = h2o.find_threshold_by_max_metric(gbm_perf_h2o, \"f1\")) +\n  labs(title = \"Precision vs Recall\", y = \"value\") +\n  theme_new\n\n\n\n\n\n\n\n4. ROC Plot\n\nensamble_h2o <- h2o.loadModel(\"../../my_models/PerfMeasures_Models/StackedEnsemble_BestOfFamily_2_AutoML_4_20230610_121831\")\n\n# deeplearning_h2o %>% h2o.saveModel(\"../../my_models/PerfMeasures_Models/\", force = T)\n# gbm_h2o %>% h2o.saveModel(\"../../my_models/PerfMeasures_Models/\", force = T)\n# ensamble_h2o %>% h2o.saveModel(\"../../my_models/PerfMeasures_Models/\", force = T)\n\nload_model_performance_metrics <- function(path, test_tbl) {\n    \n    model_h2o <- h2o.loadModel(path)\n    perf_h2o  <- h2o.performance(model_h2o, newdata = as.h2o(test_tbl)) \n    \n    perf_h2o %>%\n        h2o.metric() %>%\n        as_tibble() %>%\n        mutate(auc = h2o.auc(perf_h2o)) %>%\n        select(tpr, fpr, auc, precision, recall)\n    \n}\n\nmodel_metrics_tbl <- fs::dir_info(path = \"../../my_models/PerfMeasures_Models/\") %>%\n    select(path) %>%\n    mutate(metrics = map(path, load_model_performance_metrics, test_tbl)) %>%\n    unnest(cols = metrics)\n\n\nmodel_metrics_tbl %>%\n    mutate(\n        # Extract the model names\n        path = str_split(path, pattern = \"/\", simplify = T)[,5] %>% as_factor(),\n        auc  = auc %>% round(3) %>% as.character() %>% as_factor()\n        ) %>%\n    ggplot(aes(fpr, tpr, color = path, linetype = auc)) +\n    geom_line(size = 1) +\n    \n    # just for demonstration purposes\n    geom_abline(color = \"red\", linetype = \"dotted\") +\n    \n    theme_new +\n    theme(\n      legend.direction = \"vertical\",\n      ) +\n    labs(\n        title = \"ROC Plot\",\n        subtitle = \"Performance of 3 Models\"\n    )\n\n\n\n\n\n\n\n5. Precision vs Recall Plot\n\nmodel_metrics_tbl %>%\n    mutate(\n        path = str_split(path, pattern = \"/\", simplify = T)[,5] %>% as_factor(),\n        auc  = auc %>% round(3) %>% as.character() %>% as_factor()\n    ) %>%\n    ggplot(aes(recall, precision, color = path, linetype = auc)) +\n    geom_line(size = 1) +\n    theme_new + \n    theme(\n      legend.direction = \"vertical\",\n      ) +\n    labs(\n        title = \"Precision vs Recall Plot\",\n        subtitle = \"Performance of 3 Top Performing Models\"\n    )\n\n\n\n\n\n\n\n6. Gain Plot\n\ngain_lift_tbl <- gbm_perf_h2o %>%\n    h2o.gainsLift() %>%\n    as.tibble()\n\n## Gain Chart\n\ngain_transformed_tbl <- gain_lift_tbl %>% \n    select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift) %>%\n    select(-contains(\"lift\")) %>%\n    mutate(baseline = cumulative_data_fraction) %>%\n    rename(gain     = cumulative_capture_rate) %>%\n    # prepare the data for the plotting (for the color and group aesthetics)\n    pivot_longer(cols = c(gain, baseline), values_to = \"value\", names_to = \"key\")\n\ngain_transformed_tbl %>%\n    ggplot(aes(x = cumulative_data_fraction, y = value, color = key)) +\n    geom_line(size = 1.5) +\n    labs(\n        title = \"Gain Chart\",\n        x = \"Cumulative Data Fraction\",\n        y = \"Gain\"\n    ) +\n    theme_new\n\n\n\n\n\n\n\n7. Lift Plot\n\nlift_transformed_tbl <- gain_lift_tbl %>% \n    select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift) %>%\n    select(-contains(\"capture\")) %>%\n    mutate(baseline = 1) %>%\n    rename(lift = cumulative_lift) %>%\n    pivot_longer(cols = c(lift, baseline), values_to = \"value\", names_to = \"key\")\n\nlift_transformed_tbl %>%\n    ggplot(aes(x = cumulative_data_fraction, y = value, color = key)) +\n    geom_line(size = 1.5) +\n    labs(\n        title = \"Lift Chart\",\n        x = \"Cumulative Data Fraction\",\n        y = \"Lift\"\n    ) +\n    theme_new\n\n\n\n\n\n\n\n8. Dashboard with Cowplot\n\nplot_h2o_performance definitionplot_h2o_performance <- function(h2o_leaderboard, newdata, order_by = c(\"auc\", \"logloss\"),\n                                 max_models = 3, size = 1.5) {\n    \n    # Inputs\n    \n    leaderboard_tbl <- h2o_leaderboard %>%\n        as_tibble() %>%\n        slice(1:max_models)\n    \n    newdata_tbl <- newdata %>%\n        as_tibble()\n    \n    # Selecting the first, if nothing is provided\n    order_by      <- tolower(order_by[[1]]) \n    \n    # Convert string stored in a variable to column name (symbol)\n    order_by_expr <- rlang::sym(order_by)\n\n    # Turn of the progress bars ( opposite h2o.show_progress())\n    h2o.no_progress()\n    \n    # 1. Model metrics\n    \n    get_model_performance_metrics <- function(model_id, test_tbl) {\n        \n        model_h2o <- h2o.getModel(model_id)\n        perf_h2o  <- h2o.performance(model_h2o, newdata = as.h2o(test_tbl))\n        \n        perf_h2o %>%\n            h2o.metric() %>%\n            as.tibble() %>%\n            select(threshold, tpr, fpr, precision, recall)\n        \n    }\n    \n    model_metrics_tbl <- leaderboard_tbl %>%\n        mutate(metrics = map(model_id, get_model_performance_metrics, newdata_tbl)) %>%\n        unnest(cols = metrics) %>%\n        mutate(\n          model_id = as_factor(model_id) %>% \n                      # programmatically reorder factors depending on order_by\n                      fct_reorder(!! order_by_expr, \n                                  .desc = ifelse(order_by == \"auc\", TRUE, FALSE)),\n          auc      = auc %>% \n                      round(3) %>% \n                      as.character() %>% \n                      as_factor() %>% \n                      fct_reorder(as.numeric(model_id)),\n          logloss  = logloss %>% \n                      round(4) %>% \n                      as.character() %>% \n                      as_factor() %>% \n                      fct_reorder(as.numeric(model_id))\n        )\n    \n    \n    # 1A. ROC Plot\n    \n    p1 <- model_metrics_tbl %>%\n        ggplot(aes(fpr, tpr, color = model_id, linetype = !! order_by_expr)) +\n        geom_line(size = size) +\n        theme_new +\n        labs(title = \"ROC\", x = \"FPR\", y = \"TPR\") +\n        theme(legend.direction = \"vertical\") \n        \n    \n    # 1B. Precision vs Recall\n    \n    p2 <- model_metrics_tbl %>%\n        ggplot(aes(recall, precision, color = model_id, linetype = !! order_by_expr)) +\n        geom_line(size = size) +\n        theme_new +\n        labs(title = \"Precision Vs Recall\", x = \"Recall\", y = \"Precision\") +\n        theme(legend.position = \"none\") \n    \n    \n    # 2. Gain / Lift\n    \n    get_gain_lift <- function(model_id, test_tbl) {\n        \n        model_h2o <- h2o.getModel(model_id)\n        perf_h2o  <- h2o.performance(model_h2o, newdata = as.h2o(test_tbl)) \n        \n        perf_h2o %>%\n            h2o.gainsLift() %>%\n            as.tibble() %>%\n            select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift)\n        \n    }\n    \n    gain_lift_tbl <- leaderboard_tbl %>%\n        mutate(metrics = map(model_id, get_gain_lift, newdata_tbl)) %>%\n        unnest(cols = metrics) %>%\n        mutate(\n            model_id = as_factor(model_id) %>% \n                fct_reorder(!! order_by_expr, \n                            .desc = ifelse(order_by == \"auc\", TRUE, FALSE)),\n            auc  = auc %>% \n                round(3) %>% \n                as.character() %>% \n                as_factor() %>% \n                fct_reorder(as.numeric(model_id)),\n            logloss = logloss %>% \n                round(4) %>% \n                as.character() %>% \n                as_factor() %>% \n                fct_reorder(as.numeric(model_id))\n        ) %>%\n        rename(\n            gain = cumulative_capture_rate,\n            lift = cumulative_lift\n        ) \n    \n    # 2A. Gain Plot\n    \n    p3 <- gain_lift_tbl %>%\n        ggplot(aes(cumulative_data_fraction, gain, \n                          color = model_id, linetype = !! order_by_expr)) +\n        geom_line(size = size,) +\n        geom_segment(x = 0, y = 0, xend = 1, yend = 1, \n                     color = \"red\", size = size, linetype = \"dotted\") +\n        theme_new +\n        expand_limits(x = c(0, 1), y = c(0, 1)) +\n        labs(title = \"Gain\",\n             x = \"Cumulative Data Fraction\", y = \"Gain\") +\n        theme(legend.position = \"none\")\n    \n    # 2B. Lift Plot\n    \n    p4 <- gain_lift_tbl %>%\n        ggplot(aes(cumulative_data_fraction, lift, \n                          color = model_id, linetype = !! order_by_expr)) +\n        geom_line(size = size) +\n        geom_segment(x = 0, y = 1, xend = 1, yend = 1, \n                     color = \"red\", size = size, linetype = \"dotted\") +\n        theme_new +\n        expand_limits(x = c(0, 1), y = c(0, 1)) +\n        labs(title = \"Lift\",\n             x = \"Cumulative Data Fraction\", y = \"Lift\") +\n        theme(legend.position = \"none\") \n    \n    \n    # Combine using cowplot\n    \n    # cowplot::get_legend extracts a legend from a ggplot object\n    p_legend <- get_legend(p1)\n    # Remove legend from p1\n    p1 <- p1 + theme(legend.position = \"none\")\n    \n    # cowplot::plt_grid() combines multiple ggplots into a single cowplot object\n    p <- cowplot::plot_grid(p1, p2, p3, p4, ncol = 2)\n    \n    # cowplot::ggdraw() sets up a drawing layer\n    p_title <- ggdraw() + \n    \n        # cowplot::draw_label() draws text on a ggdraw layer / ggplot object\n        draw_label(\"H2O Model Metrics\", size = 18, fontface = \"bold\", \n                   color = \"#2C3E50\")\n    \n    p_subtitle <- ggdraw() + \n        draw_label(glue(\"Ordered by {toupper(order_by)}\"), size = 10,  \n                   color = \"#2C3E50\")\n    \n    # Combine everything\n    ret <- plot_grid(p_title, p_subtitle, p, p_legend, \n    \n                     # Adjust the relative spacing, so that the legends always fits\n                     ncol = 1, rel_heights = c(0.05, 0.05, 1, 0.05 * max_models))\n    \n    h2o.show_progress()\n    \n    return(ret)\n    \n}\n\n\n\nautoml_models_h2o@leaderboard %>%\n    plot_h2o_performance(newdata = test_tbl, order_by = \"logloss\", \n                         size = 0.5, max_models = 4)"
  },
  {
    "objectID": "content/01_journal/06_explaining_black_box_models_with_lime.html",
    "href": "content/01_journal/06_explaining_black_box_models_with_lime.html",
    "title": "Explaining Black-Box Models with LIME",
    "section": "",
    "text": "Repeat of previous Sections\n\nShow the code# LIME FEATURE EXPLANATION ----\n\n# 1. Setup ----\n\n# Load Libraries \n\nlibrary(h2o)\nlibrary(rsample)\nlibrary(recipes)\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(tidyquant)\nlibrary(lime)\n\n# Load Data\nemployee_attrition_tbl <- read.csv(\"../../../employee_attrition.csv\")\n\npath_data_definitions <- \"../../../data_definitions.xlsx\"\ndefinitions_raw_tbl   <- read_excel(path_data_definitions, sheet = 1, col_names = FALSE)\n\nprocess_hr_data_readable <- function(data, definitions_tbl) {\n  \n  definitions_list <- definitions_tbl %>%\n    fill(...1, .direction = \"down\") %>%\n    filter(!is.na(...2)) %>%\n    separate(...2, into = c(\"key\", \"value\"), sep = \" '\", remove = TRUE) %>%\n    rename(column_name = ...1) %>%\n    mutate(key = as.numeric(key)) %>%\n    mutate(value = value %>% str_replace(pattern = \"'\", replacement = \"\")) %>%\n    split(.$column_name) %>%\n    map(~ select(., -column_name)) %>%\n    map(~ mutate(., value = as_factor(value))) \n  \n  for (i in seq_along(definitions_list)) {\n    list_name <- names(definitions_list)[i]\n    colnames(definitions_list[[i]]) <- c(list_name, paste0(list_name, \"_value\"))\n  }\n  \n  data_merged_tbl <- list(HR_Data = data) %>%\n    append(definitions_list, after = 1) %>%\n    reduce(left_join) %>%\n    select(-one_of(names(definitions_list))) %>%\n    set_names(str_replace_all(names(.), pattern = \"_value\", \n                              replacement = \"\")) %>%\n    select(sort(names(.))) %>%\n    mutate_if(is.character, as.factor) %>%\n    mutate(\n      BusinessTravel = BusinessTravel %>% fct_relevel(\"Non-Travel\", \n                                                      \"Travel_Rarely\", \n                                                      \"Travel_Frequently\"),\n      MaritalStatus  = MaritalStatus %>% fct_relevel(\"Single\", \n                                                     \"Married\", \n                                                     \"Divorced\")\n    )\n  \n  return(data_merged_tbl)\n  \n}\n\nemployee_attrition_readable_tbl <- process_hr_data_readable(employee_attrition_tbl, definitions_raw_tbl)\n\n# Split into test and train\nset.seed(seed = 1113)\nsplit_obj <- rsample::initial_split(employee_attrition_readable_tbl, prop = 0.85)\n\n# Assign training and test data\ntrain_readable_tbl <- training(split_obj)\ntest_readable_tbl  <- testing(split_obj)\n\n# ML Preprocessing Recipe \nrecipe_obj <- recipe(Attrition ~ ., data = train_readable_tbl) %>%\n                step_zv(all_predictors()) %>%\n                step_mutate_at(c(\"JobLevel\", \"StockOptionLevel\"), fn = as.factor) %>% \n                prep()\n\nrecipe_obj\n\ntrain_tbl <- bake(recipe_obj, new_data = train_readable_tbl)\ntest_tbl  <- bake(recipe_obj, new_data = test_readable_tbl)\n\n# 2. Models ----\n\nh2o.init()\n\nautoml_leader <- h2o.loadModel(\"../../my_models/Attr_Model/StackedEnsemble_AllModels_3_AutoML_1_20230611_110811\")\n\n\nExplanation\n\npredictions_tbl <- automl_leader %>% \n  h2o.predict(newdata = as.h2o(test_tbl)) %>% \n  as_tibble() %>% \n  bind_cols(\n    test_tbl %>% \n      select(Attrition, EmployeeNumber)\n  )\n\n\nexplainer <- train_tbl %>% \n  select(-Attrition) %>% \n  lime(\n    model = automl_leader,\n    bin_continuous = TRUE,\n    n_bins = 4,\n    quantile_bins = TRUE\n  )\n\n\nexplanation <- test_tbl %>% \n  slice(1:20) %>% \n  select(-Attrition) %>% \n  lime::explain(\n    explainer = explainer,\n    n_labels = 1,\n    n_features = 8,\n    n_permutations = 5000,\n    kernel_width = 1.0\n  )\n\nChallenge, Part 1\n\ncustom_plot_features <- function(explanation, case_id) {\n  \n  case_expl <- explanation %>% \n    filter(case == case_id) %>% \n    as_tibble() %>% \n    arrange(feature_weight %>% abs()) %>%\n    mutate(feature_desc = as_factor(feature_desc)) %>% \n    mutate(is_support = feature_weight > 0)\n  \n  label <- case_expl$label[1]\n  probability <- round(case_expl$label_prob[1], digits = 2)\n  explanation_fit <- round(case_expl$model_r2[1], digits = 2)\n  \n  case_expl %>%   \n    ggplot() +\n    \n    geom_col(aes(x = feature_desc, y = feature_weight, fill = is_support)) +\n    \n    coord_flip() +\n    \n    scale_fill_discrete(labels = c(\"Contradicts\", \"Supports\")) +\n    \n    labs(\n      subtitle = str_c(paste0(\"Case: \", case_id),\n                       paste0(\"Label: \", label),\n                       paste0(\"Probability: \", probability),\n                       paste0(\"Explanation Fit: \", explanation_fit),\n                       sep = \"\\n\"),\n      x = \"Feature\",\n      y = \"Weight\"\n    ) +\n    \n    theme(\n      legend.title = element_blank(),\n      legend.position = \"bottom\"\n    )\n}\n\n\ncustom_plot_features(explanation, 8)\n\n\n\n\n\n\n\nChallenge, Part 2\n\nexplanation %>% \n  mutate(case = as_factor(case)) %>% \n  \n  ggplot(aes(x = case, y = feature_desc, fill = feature_weight)) +\n  \n  geom_tile() +\n  \n  facet_wrap(vars(label)) +\n  \n  scale_fill_continuous(name = \"Feature weight\") +\n  \n  labs(\n    x = \"Case\",\n    y = \"Feature\",\n  ) +\n  \n  theme(\n    axis.text.x = element_text(angle=45, hjust=1),\n    panel.grid = element_blank(),\n    panel.border = element_rect(color = \"black\", fill = \"transparent\"),\n    strip.background = element_blank(),\n    strip.text = element_text(hjust = 0.0)\n    )"
  },
  {
    "objectID": "content/02_notes/07_class_notes.html",
    "href": "content/02_notes/07_class_notes.html",
    "title": "Class Notes",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.1     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nlibrary(readxl)\n\nemployee_attrition_tbl <- read.csv(\"../../../employee_attrition.csv\")\n\npath_data_definitions <- \"../../../data_definitions.xlsx\"\ndefinitions_raw_tbl   <- read_excel(path_data_definitions, sheet = 1, col_names = FALSE)\n\nNew names:\n• `` -> `...1`\n• `` -> `...2`\n\ndefinitions_tbl <- definitions_raw_tbl %>% \n  fill(...1, .direction = \"down\") %>% \n  filter(!is.na(...2)) %>% \n  separate(...2, into = c(\"key\", \"value\"), sep = \" '\", remove = TRUE) %>% \n  rename(column_name = ...1) %>% \n  mutate(key = as.numeric(key)) %>% \n  mutate(value = value %>% str_replace(pattern = \"'\", replacement = \"\"))\n\n\ndefinitions_list <- definitions_tbl %>% \n  split(.$column_name) %>% \n  map(~ select(., -column_name)) %>% \n  map(~ mutate(., value = as_factor(value)))\n\n\nfor (i in seq_along(definitions_list)) {\n  list_name <- names(definitions_list)[i]\n  colnames(definitions_list[[i]]) <- c(list_name, paste0(list_name, \"_value\"))\n}\n\n\ndata_merged_tbl <- list(HR_Data = employee_attrition_tbl) %>% \n  append(definitions_list, after = 1) %>% \n  reduce(left_join) %>% \n  select(-one_of(names(definitions_list))) %>% \n  set_names(str_replace_all(names(.), pattern = \"_value\", replacement = \"\")) %>% \n  select(sort(names(.)))\n\nJoining with `by = join_by(Education)`\nJoining with `by = join_by(EnvironmentSatisfaction)`\nJoining with `by = join_by(JobInvolvement)`\nJoining with `by = join_by(JobSatisfaction)`\nJoining with `by = join_by(PerformanceRating)`\nJoining with `by = join_by(RelationshipSatisfaction)`\nJoining with `by = join_by(WorkLifeBalance)`\n\ndata_processed_tbl <- data_merged_tbl %>%\n  mutate_if(is.character, as.factor) %>% \n  mutate(\n    BusinessTravel = BusinessTravel %>% fct_relevel(\"Non-Travel\",\n                                                    \"Travel_Rarely\",\n                                                    \"Travel_Frequently\"),\n    MaritalStatus = MaritalStatus %>% fct_relevel(\"Single\",\n                                                  \"Married\",\n                                                  \"Divorced\")\n    )\n\ndata_processed_tbl %>% \n  select_if(is.factor) %>% \n  map(levels)\n\n$Attrition\n[1] \"No\"  \"Yes\"\n\n$BusinessTravel\n[1] \"Non-Travel\"        \"Travel_Rarely\"     \"Travel_Frequently\"\n\n$Department\n[1] \"Human Resources\"        \"Research & Development\" \"Sales\"                 \n\n$Education\n[1] \"Below College\" \"College\"       \"Bachelor\"      \"Master\"       \n[5] \"Doctor\"       \n\n$EducationField\n[1] \"Human Resources\"  \"Life Sciences\"    \"Marketing\"        \"Medical\"         \n[5] \"Other\"            \"Technical Degree\"\n\n$EnvironmentSatisfaction\n[1] \"Low\"       \"Medium\"    \"High\"      \"Very High\"\n\n$Gender\n[1] \"Female\" \"Male\"  \n\n$JobInvolvement\n[1] \"Low\"       \"Medium\"    \"High\"      \"Very High\"\n\n$JobRole\n[1] \"Healthcare Representative\" \"Human Resources\"          \n[3] \"Laboratory Technician\"     \"Manager\"                  \n[5] \"Manufacturing Director\"    \"Research Director\"        \n[7] \"Research Scientist\"        \"Sales Executive\"          \n[9] \"Sales Representative\"     \n\n$JobSatisfaction\n[1] \"Low\"       \"Medium\"    \"High\"      \"Very High\"\n\n$MaritalStatus\n[1] \"Single\"   \"Married\"  \"Divorced\"\n\n$Over18\n[1] \"Y\"\n\n$OverTime\n[1] \"No\"  \"Yes\"\n\n$PerformanceRating\n[1] \"Low\"         \"Good\"        \"Excellent\"   \"Outstanding\"\n\n$RelationshipSatisfaction\n[1] \"Low\"       \"Medium\"    \"High\"      \"Very High\"\n\n$WorkLifeBalance\n[1] \"Bad\"    \"Good\"   \"Better\" \"Best\""
  },
  {
    "objectID": "content/03_other/08_links.html",
    "href": "content/03_other/08_links.html",
    "title": "Links",
    "section": "",
    "text": "R is a free open-source programming language that can be used for statistical analysis, data-simulation, graphing, and lots of other stuff. Another free program is R-studio, that provides a nice graphic interface for R. Download R first, then download R-studio. Both can run on PCs, Macs or Linux. Students will be learning R in the stats labs using the lab manual .\n\n\n\n\nGoogle is great, Google your problem\nStackoverflow is great, google will often take you there because someone has already asked your question, and someone else has answered, usually many people have answered your question many ways."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Lab Journal",
    "section": "",
    "text": "This is a template example for lab journaling. Students in the data science courses at the Institute of Entrepreneurship will use this template to learn R for business analytics. Students can replace this text as they wish."
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "My Lab Journal",
    "section": "How to use",
    "text": "How to use\n\nAccept the assignment and get your own github repo.\nBlog/journal what you are doing in R, by editing the .qmd files.\nSee the links page for lots of helpful links on learning R.\nChange everything to make it your own.\nMake sure to render you website everytime before you want to upload changes"
  }
]